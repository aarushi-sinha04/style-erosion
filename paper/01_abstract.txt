Authorship verification—determining whether two texts were written by the same author—is essential for forensic linguistics, plagiarism detection, and cybersecurity. While deep learning achieves >90% accuracy on single-domain benchmarks (PAN competitions), real-world deployment must contend with two underexplored challenges: generalizing across text domains and resisting adversarial manipulation through AI-generated paraphrasing.

We present the first systematic characterization of the accuracy–robustness trade-off in authorship verification, examining how feature granularity determines a model's vulnerability to paraphrase attacks. We evaluate seven models—spanning character n-grams, syntactic features (POS trigrams, readability metrics), and hybrid architectures—across three domains: fanfiction (PAN22), blogs (BlogText), and emails (Enron).

Our key finding is a fundamental dichotomy: character 4-gram models achieve 86.2% cross-domain accuracy but suffer 74.0% attack success rate under T5 paraphrasing, while syntactic models achieve only 60.4% accuracy but maintain 7.7% attack success rate. We introduce Rob Siamese, an adversarially fine-tuned cross-domain Siamese network achieving state-of-the-art cross-domain accuracy (99.4% PAN22, 87.2% Enron, 71.9% Blog). Through ablation studies, we demonstrate that adversarial training improves clean accuracy by 5.6 percentage points but cannot overcome feature-level vulnerability to text transformation. BERTScore evaluation (F1=0.885) confirms that attacks preserve semantic meaning while successfully deceiving character-based models.

Our work provides an empirical framework for practitioners to select feature representations based on deployment scenario: character n-grams for high-accuracy forensics, syntactic features for adversarial environments, or hybrid ensembles for balanced trade-offs. Error analysis reveals that Blog texts present the greatest challenge, with 77% of all errors concentrated in this domain due to high stylistic variance among authors.

Keywords: Authorship Verification, Adversarial Robustness, Stylometry, Cross-Domain Generalization, Paraphrasing Attacks, Feature Engineering
